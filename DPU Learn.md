# 论文学习
## Corundum: An Open-Source 100-Gbps NIC

**摘要**：Corundum是一个基于FPGA的开源网络接口开发平台，支持高达100 Gbps及更高速率的网络接口开发。该平台包含多项核心功能以实现实时、高线速操作，包括：高性能数据路径、10G/25G/100G以太网MAC、PCI Express Gen 3、定制的PCIe DMA引擎，以及原生高精度IEEE 1588 PTP时间戳功能。其关键特性是可扩展的队列管理，支持超过10,000个队列与可扩展的传输调度器，从而实现对数据包传输的细粒度硬件控制。结合多网络接口、每接口多端口以及基于事件的端口级传输调度功能，这些特性为开发先进的网络接口、架构和协议提供了可能。软件层面通过一个针对Linux网络栈的高性能驱动与硬件交互，同时支持分散/聚集DMA、校验和卸载、接收流哈希和接收侧扩展功能。此外，平台提供了一个全面的开源Python仿真框架，覆盖从驱动和PCIe接口到以太网接口的全系统模拟，极大简化了开发和调试流程。Corundum的强大能力与灵活性通过一个微秒级精度的时分多址（TDMA）硬件调度器实现得到验证，该调度器可在100 Gbps线速下无CPU开销地执行TDMA调度。

### I. 引言与背景

网络接口控制器（NIC）是计算机与网络交互的网关。NIC在软件栈和网络之间架起桥梁，其功能定义了网络接口。网络接口的功能及其实现方式正在快速演进，这些变化由两大需求驱动：不断提升的线路速率，以及支持高性能分布式计算和虚拟化的NIC特性。更高的线路速率使得许多NIC功能必须通过硬件而非软件实现。同时，实现高级协议和网络架构需要精确的多队列传输控制等新型网络功能。

为满足在真实线路速率下开发新型网络协议和架构的开放平台需求，我们开发了一款开源的高性能FPGA基NIC原型平台Corundum。该平台支持至少94 Gbps的速率，完全开源，其驱动可跨完整网络栈使用。设计兼具可移植性和紧凑性，支持多种设备，即使在较小器件上也能保留充足资源供进一步定制。Corundum的模块化设计和可扩展性支持硬件/软件协同优化，为高级网络应用的开发和测试提供了真实环境。

### A. 动机与既有工作

通过分析现有NIC设计中硬件与软件的功能划分，可以理解开发Corundum的动机。NIC硬件功能分为两类：第一类是减轻CPU逐包处理负担的简单卸载功能（如校验和/哈希计算、分段卸载）；第二类是为实现高性能和公平性必须在硬件实现的功能（如流导向、速率限制、负载均衡和时间戳）。

传统NIC硬件功能由专用集成电路（ASIC）实现，虽能低成本高性能运行，但扩展性有限，新增功能的开发周期长且昂贵。智能NIC通过可编程处理核心和硬件原语提供灵活性，但难以支持高线路速率[1]。软件NIC通过软件实现网络功能，虽开发快捷但需消耗CPU资源且难以保证全速运行，也无法实现精确传输控制[2]。尽管存在这些限制，许多研究仍通过修改网络栈或使用DPDK等内核旁路框架在软件中实现新功能[3]-[7]。

FPGA基NIC结合了ASIC的高性能和软件NIC的灵活性：支持全线路速率、低延迟和精确时序，同时开发周期较短。阿里云等厂商开发了专有FPGA基RDMA NIC[8]，商业产品如Exablaze[9]和Netcope[10]也存在，但它们多为闭源"黑盒"，限制了新网络应用的开发灵活性。

现有高性能DMA组件（如Xilinx XDMA/QDMA核）对传输数据流的控制能力有限：XDMA核仅支持少量队列且无调度控制；QDMA和Arkville核虽面向网络应用，但分别仅支持2K和128队列，且缺乏精确传输控制方法。开源项目NetFPGA[12]提供通用FPGA报文处理工具，但其参考设计采用非网络优化的XDMA核。Catapult[13]和FlowBlaze[14]等方案将标准NIC功能交由独立ASIC实现，无法控制调度器或队列。

其他项目如Shoal、SENIC、PIEO、NDP和Loom采用部分硬件或纯软件实现，但均未在标准网络栈下实现全功能整合。Corundum的独特之处在于完全开源、支持标准网络栈下的实用线路速率，通过数千个传输队列与可扩展调度器实现细粒度流控制，成为结合硬件/软件功能的强大开发平台。

### II. 实现

Corundum具有多项独特的架构特性。首先，硬件队列状态被高效存储在FPGA的块RAM中，支持数千个独立可控队列。这些队列与接口关联，每个接口可包含多个端口，每个端口拥有独立的传输调度器，从而实现对数据包传输的极细粒度控制。调度器模块支持完全替换，可实验不同调度方案（如基于PTP时间同步的高精度TDMA）。

Corundum采用模块化参数化设计，通过Verilog参数可配置接口/端口数量、队列数、内存大小等。配置寄存器暴露参数信息，驱动无需修改即可适配不同硬件平台。当前设计支持Xilinx Ultrascale PCIe硬核，未来将扩展至更多FPGA平台。其资源占用较小，例如在Kintex Ultrascale KU035 FPGA上仅占用不到25%逻辑资源。

### A. 高层架构

如图1所示，Corundum NIC包含三级嵌套模块：

1. **顶层模块**：集成PCIe硬核、DMA接口、PTP时钟和以太网MAC/PHY。
2. **接口模块**：对应操作系统级网络接口（如eth0），管理队列状态和描述符处理。
3. **端口模块**：提供AXI Stream接口至MAC，包含调度器、收发引擎和数据路径。

### B. 流水线队列管理

通过描述符队列（主机→NIC）和完成队列（NIC→主机）协调数据传输。队列状态（128位/队列）存储在BRAM/URAM中，4096队列仅需2个URAM实例。流水线架构支持并行操作，包含四种操作：寄存器读写、出队/入队请求与提交。

### C. 传输调度器

默认采用轮询调度器（tx_scheduler_rr），其状态信息同样存储在BRAM/URAM中。调度器模块包含：

- AXI Lite接口：配置参数和队列开关。
- 流接口：接收驱动门铃事件、发送调度命令、反馈传输状态。

  支持替换为自定义调度算法（如TDMA、HPCC拥塞控制）。


### D. 端口与接口

突破传统NIC单端口单接口的限制（图2a），支持多端口绑定至同一接口（图2b）。所有端口共享传输队列，操作系统视为统一接口，通过硬件调度器实现流量的动态迁移和负载均衡，适用于P-FatTree等新型网络架构。

### E. 数据路径与收发引擎

- **接口标准**：AXI Stream用于以太网数据流，自定义分段内存接口连接PCIe DMA。
- **时钟域**：核心逻辑运行于250 MHz PCIe时钟，MAC接口异步转换（如100G CMAC运行于322 MHz）。
- **引擎功能**：
 - 发送引擎：协调校验和模块、MAC/PHY，记录PTP时间戳。
 - 接收引擎：处理流哈希，将数据写入主机内存。

### F. 分段内存接口

将PCIe接口宽度分段（如512位→8×128位），消除对齐压力，实现每周期全带宽非对齐访问。特点包括：

- 独立流控与操作排序。
- 基于选择信号（非地址解码）的路由机制。
- 字节地址映射：低4位选择段内字节，中间3位选择段，高位选择段内字地址。

### G. 设备驱动

Linux内核模块自动检测NIC参数（接口数、队列数等），管理DMA缓冲区和中断。驱动与硬件解耦，适配不同FPGA平台无需修改。

### H. 仿真框架

基于Python/MyHDL的全系统仿真，包含：

- PCIe基础设施模型（4500行代码）：根复合体、端点、中断等。
- FPGA硬核模型（4000行代码）：与Verilog设计协同仿真。

  支持快速验证不同长度数据包的收发功能。


### III. 测试结果

Corundum的100G版本在Alpha Data ADM-PCIE-9V3开发板上进行测试（搭载于双路Xeon 6138服务器），通过QSFP28铜缆连接Mellanox ConnectX-5商用NIC对比。测试使用多实例iperf3饱和链路：

1. **大包性能（MTU=9000字节）**
 - 单方向：Corundum达到95.5 Gbps（接收）/94.4 Gbps（发送），Mellanox CX5为97.8 Gbps（双向）。
 - 全双工：Corundum降至65.7/85.9 Gbps，Mellanox CX5降至83.4 Gbps，表明当前Linux内核驱动存在瓶颈。
2. **小包性能（MTU=1500字节）**
 - 单方向：Corundum为75.0/72.2 Gbps，Mellanox CX5为93.4/86.5 Gbps。
 - 提升并行传输数（8→16）后，Corundum性能从65.6/45.7 Gbps改善至75.0/72.2 Gbps，验证PCIe往返延迟是主要限制。
3. **PTP时间同步**
 - 在10G模式下，通过Arista 40G交换机作为PTP边界时钟，实现硬件时钟同步精度优于50 ns，且链路饱和时性能不变。

### IV. 案例研究：时分多址（TDMA）

Corundum通过万级队列和PTP同步实现高精度TDMA：

- **设计原理**：
 - 调度器控制模块以250 MHz运行，按PTP时间启用/禁用队列（每条队列操作耗时4 ns）。
 - 时隙长度需预留队列切换时间（如256队列禁用需1 μs）。
- **性能指标**：
 - **100G模式**：200 μs周期内划分两个100 μs时隙，控制精度达1.4 μs（2个数据包传输时间）。
 - **10G模式**：相同周期下精度为2.4 μs。





# 前置知识准备
## axis axi4 axilite（可选）协议需要大致理解，请注意，axis协议是corundum的主要传输协议，务必掌握


AXI4-Stream 是 AMBA（Advanced Microcontroller Bus Architecture）接口标准的一种，专门设计用于高性能、低延迟的通信需求，特别是在数字信号处理和视频流传输等领域。AXI4-Stream 协议主要用于在 FPGA（Field-Programmable Gate Array）和其他类型的数字硬件之间传输数据流。

AXI4-Stream 协议的主要特点包括：
流传输：AXI4-Stream 支持连续的、单向的数据流传输，适用于视频流、音频流或其他连续数据流的传输。

低延迟：通过支持突发传输（burst transfers），AXI4-Stream 能够在保持数据完整性的同时，减少传输延迟。

可配置性：AXI4-Stream 提供了多种配置选项，如数据宽度（8位、16位、32位、64位等）、传输速率等，以适应不同的应用需求。

灵活性：它支持多种传输模式，包括单向（单向传输）、单向可变（单向传输，但突发长度可变）和双向（全双工传输）。

AXI4-Stream 协议的关键参数和信号包括：
TVALID：表示传输通道中有有效数据。

TREADY：表示接收方准备好接收数据。

TDATA：携带数据的总线，其宽度根据设计需求确定。

TKEEP：指示哪些位是有效的，用于打包和解包操作。

TLAST：表示传输中的最后一个数据包。

TUSER：用户定义的信号，可用于携带额外的控制或状态信息。

TSTRB：字节使能信号，指示哪些字节是有效的。

使用示例
在 FPGA 或 SoC（System on Chip）设计中，AXI4-Stream 通常用于连接视频编解码器、图像处理器或其他需要高速数据流的应用模块。例如，一个视频流处理器可能使用 AXI4-Stream 从摄像头捕获原始视频数据，然后进行处理并输出到显示器或其他输出设备。

配置示例
假设你有一个 32 位宽的数据总线，你想配置一个 AXI4-Stream 接口：
```verilog
module axi_stream_interface (
    input wire aclk,           // 时钟信号
    input wire aresetn,        // 异步复位信号，低电平有效
    input wire [31:0] tdata,   // 数据总线
    input wire tvalid,         // 数据有效信号
    output wire tready,        // 数据接收准备好信号
    input wire [3:0] tkeep,    // 字节使能信号
    input wire tlast,          // 最后一个数据包信号
    input wire [0:0] tuser     // 用户定义信号
);
    // 在这里实现你的逻辑
endmodule
```

2. 学习计算机组成原理对开发riscv部分是有帮助的，至少要知道riscv core的组成部分，如何去修改DTS，还有openocd的概念与使用：有时间可以看看一生一芯
### RISC-V core
#### 取指单元
功能：从内存读取指令（通过ICache或AXI总线）；处理指令地址预测（PC+4或分支预测）
关键组件：PC寄存器：存储当前指令地址
分支预测器（可选）：静态预测（总是跳转）或动态预测（BHT）
典型代码：
```verilog
always @(posedge clk) begin
  if (branch_taken) pc <= branch_target;
  else pc <= pc + 4;
end
```

#### 译码单元
功能：解析32位指令（识别opcode/funct3/funct7）；读取寄存器堆（RegFile）数据
关键逻辑：立即数生成：支持I/S/B/U/J型立即数；控制信号生成：ALU操作类型、内存访问类型等
RISC-V指令格式示例：
```text
add x1, x2, x3  => [31:25]=0, [24:20]=x3, [19:15]=x2, [14:12]=0, [11:7]=x1, [6:0]=0110011
```

#### 执行单元
ALU子系统：支持算术运算（ADD/SUB）、逻辑运算（AND/OR/XOR）；可扩展乘法器（M扩展）和除法器
分支处理：计算分支目标地址（PC + imm_b）；比较条件（BEQ/BNE/BLT等）
数据通路示例：
```text
alu_result = (op_add) ? (rs1 + rs2) : 
            (op_sub) ? (rs1 - rs2) :
            (op_and) ? (rs1 & rs2) : ...;
```

#### 访存单元
功能：处理内存读写（通过DCache或AXI总线）；对齐检查（RISC-V要求自然对齐）
访问类型：LB/LH/LW（加载字节/半字/字）；SB/SH/SW（存储字节/半字/字）
原子操作：LR/SC（Load-Reserved/Store-Conditional）；AMOADD/AMOXOR等

#### 写回单元
数据选择器： ALU结果、内存加载数据、CSR读取数据
冲突处理： 检测RAW（Read After Write）冲突；通过流水线停顿或数据旁路解决

3. 网络驱动开发基础请大致了解，理解网卡的5个队列：发送/接收 ，发送完成、接收完成，事件队列
### 发送队列
#### 功能：存储主机准备发送出去的数据包
#### 工作流程：
  操作系统将待发送的数据包描述符放入发送队列
  网卡从队列中取出描述符并获取实际数据包
  网卡将数据包发送到网络
#### 特点：通常有多个发送队列以实现多队列并行处理

### 接收队列
#### 功能：存储从网络到达的数据包
#### 工作流程：
  网卡接收到数据包后，将其放入接收队列
  操作系统从队列中读取数据包描述符
  系统通过DMA获取实际数据包内容
#### 特点：现代网卡支持多队列接收，可实现RSS(接收侧缩放)将流量分散到不同CPU核心

### 发送完成队列
#### 功能：通知主机发送操作已完成
#### 工作流程：
  网卡成功发送数据包后，在发送完成队列中放置完成通知
  主机通过轮询或中断方式获知发送完成
  主机可以释放相关资源(如DMA缓冲区)
#### 重要性：避免过早释放资源导致的数据损坏

### 接收完成队列
#### 功能：通知主机有新数据包到达
#### 工作流程：
  网卡将接收到的数据包放入接收缓冲区后
  在接收完成队列中放置完成通知
  主机通过轮询或中断方式获知新数据包到达

### 事件队列
#### 功能：处理网卡的各种异步事件
#### 典型事件：
  链路状态变化(连接/断开)
  错误条件(如DMA错误)
  队列溢出或其他异常情况
  热插拔事件
#### 重要性：提供网卡状态监控和错误处理机制

### 队列协同工作流程
#### 发送流程：
  应用数据 → 内核协议栈 → 放入TX队列 → 网卡发送
  发送完成 → TX完成队列通知 → 释放资源
#### 接受流程
  网卡接收数据 → 放入RX队列 → RX完成队列通知
  内核读取数据 → 传递给上层应用
#### 事件处理
  网卡检测到事件 → 放入事件队列 → 触发中断或通知
  驱动处理相应事件

### 性能优化考虑
#### 多队列设计
  现代网卡支持多队列，可实现：
  RSS (Receive Side Scaling) - 基于哈希将流量分散到不同CPU
  消除锁竞争，提高并行性
#### 轮询vs中断
  高负载下轮询(DPDK风格)性能更好
  低负载下中断更节能
#### DMA使用
  队列描述符通常通过DMA与主机内存交互，减少CPU开销
4. 需要能看懂dpdk代码：请参考学长学姐的笔记

5. verilog的基本语法，基本激励文件编写

6. 对于应用层：根据自己的应用学习相关的知识，比如spark
### Spark核心概念
#### RDD（弹性分布式数据集）
创建方式：paralleize（），textFile()等。  

转换操作：(map、filter、flatMap)与行动操作 (count、collect、reduce)。  

持久化策略(cache()、persist())。  

宽依赖与窄依赖。
#### 实际案例
```python
# 统计文本词频
text_file = sc.textFile("hdfs://...")
counts = text_file.flatMap(lambda line: line.split(" ")) \
                 .map(lambda word: (word, 1)) \
                 .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile("hdfs://...")
```

### DataFrame ALI
#### 核心概念 
创建DataFrame(从RDD、CSV、JSON等)

常用操作：select、filter、groupBy、agg

UDF函数编写

数据缓存：df.cache()


#### 案例示例
```python
from pyspark.sql import functions as F
  
df = spark.read.csv("data.csv", header=True)
result = df.groupBy("department").agg(
    F.avg("salary").alias("avg_salary"),
    F.max("age").alias("max_age")
)
```


## RISC-V
### 简单就是美——RISC-V架构的设计哲学
RISC-V架构作为一种指令集架构，在介绍细节之前，让我们先了解设计的哲学。所谓设计的“哲学”便是其推崇的一种策略，譬如说我们熟知的日本车的设计哲学是经济省油，美国车的设计哲学是霸气外漏等。RISC-V架构的设计哲学是什么呢？是“大道至简”。

笔者最为推崇的一种设计原则便是：简单就是美，简单便意味着可靠。无数的实际案例已经佐证了“简单即意味着可靠的”真理，反之越复杂的机器越则越容易出错。

所谓大道至简，在IC设计的实际工作中，笔者曾见过最简洁的设计实现安全可靠，也曾见过最繁复的设计长时间无法稳定收敛。最简洁的设计往往是最可靠的，在大多数的项目实践中一次次的得到检验。

IC设计的工作性质非常特殊，其最终的产出是芯片，而一款芯片的设计和制造周期均很长，无法像软件代码那样轻易的升级和打补丁，每一次芯片的改版到交付都需要几个月的周期。不仅如此，芯片的一次制造成本费用高昂，从几十万美金到百千万美金不等。这些特性都决定了IC设计的试错成本极为高昂，因此能够有效的降低错误的发生就显得非常的重要。

现代的芯片设计规模越来越大，复杂度越来越高，并不是说要求设计者一味的逃避使用复杂的技术，而是应该将好钢用在刀刃上，将最复杂的设计用在最为关键的场景，在大多数有选择的情况下，尽量选择简洁的实现方案。

笔者在第一次阅读了RISC-V架构文档之时，不禁击节赞叹，拍案惊奇，因为RISC-V架构在其文档中不断地明确强调，其设计哲学是“大道至简”，力图通过架构的定义使得硬件的实现足够简单。其简单就是美的哲学，可以从几个方面容易看出，后续小节将一一加以论述。

1.1 无病一身轻——架构的篇幅

在处理器领域，目前主流的架构为x86与ARM架构，笔者曾经参与设计ARM架构的应用处理器，因此需要阅读ARM的架构文档，如果对其熟悉的读者应该了解其篇幅。经过几十年的发展，现代的x86与ARM架构的架构文档长达几百数千页。打印出来能有半个桌子高，可真是“著作等身”。

之所以现代x86与ARM架构的文档长达数千页，且版本众多，一个主要的原因是因为其架构的发展的过程也伴随了现代处理器架构技术的不断发展成熟。

并且作为商用的架构，为了能够保持架构的向后兼容性，其不得不保留许多过时的定义，或者在定义新的架构部分时为了能够将就已经存在的技术部分而显得非常的别扭。久而久之就变得极为冗长。

那么现代成熟的架构是否能够选择重新开始，重新定义一个简洁的架构呢，可以说是几乎不可能。其中一个重要的原因便是其无法向前兼容，从而无法得到用户的接受。试想一下如果我们买了一款新的搭配新的处理器的电脑或者手机回家，之前所有的软件都无法运行而变砖，那肯定是无法让人接受的。

而现在才推出的RISC-V架构，则具备了后发优势，由于计算机体系结构经过多年的发展已经成为比较成熟的技术，多年来在不断成熟的过程中暴露的问题都已经被研究透彻，因此新的RISC-V架构能够加以规避，并且没有背负向后兼容的历史包袱，可以说是无病一身轻。

目前的“RISC-V架构文档”分为“指令集文档”（riscv-spec-v2.2.pdf）和“特权架构文档”（riscv-privileged-v1.10.pdf）。“指令集文档”的篇幅为145页，而“特权架构文档”的篇幅也仅为91页。熟悉体系结构的工程师仅需一至两天便可将其通读，虽然“RISC-V的架构文档”还在不断地丰富，但是相比“x86的架构文档”与“ARM的架构文档”，RISC-V的篇幅可以说是极其短小精悍。

感兴趣的读者可以在RISC-V基金会的网站上（https://riscv.org/specifications/）无需注册便可免费下载其文档，如图1所示。

1.2 能屈能伸——模块化的指令集

RISC-V架构相比其他成熟的商业架构的最大一个不同还在于它是一个模块化的架构。因此，RISC-V架构不仅短小精悍，而且其不同的部分还能以模块化的方式组织在一起，从而试图通过一套统一的架构满足各种不同的应用。

这种模块化是x86与ARM架构所不具备的。以ARM的架构为例，ARM的架构分为A、R和M三个系列，分别针对于Application（应用操作系统）、Real-Time（实时）和Embedded（嵌入式）三个领域，彼此之间并不兼容。

但是模块化的RISC-V架构能够使得用户能够灵活选择不同的模块组合，以满足不同的应用场景，可以说是“老少咸宜”。譬如针对于小面积低功耗嵌入式场景，用户可以选择RV32IC组合的指令集，仅使用Machine Mode（机器模式）；而高性能应用操作系统场景则可以选择譬如RV32IMFDC的指令集，使用Machine Mode（机器模式）与User Mode（用户模式）两种模式。而他们共同的部分则可以相互兼容。

1.3 浓缩的都是精华——指令的数量

短小精悍的架构以及模块化的哲学，使得RISC-V架构的指令数目非常的简洁。基本的RISC-V指令数目仅有40多条，加上其他的模块化扩展指令总共几十条指令。

### RISC-V指令集架构简介
本章将对RISC-V的指令集架构多方面的特性进行简要介绍。

2.1 模块化的指令子集

RISC-V的指令集使用模块化的方式进行组织，每一个模块使用一个英文字母来表示。RISC-V最基本也是唯一强制要求实现的指令集部分是由I字母表示的基本整数指令子集，使用该整数指令子集，便能够实现完整的软件编译器。其他的指令子集部分均为可选的模块，具有代表性的模块包括M/A/F/D/C

为了提高代码密度，RISC-V架构也提供可选的“压缩”指令子集，由英文字母C表示。压缩指令的指令编码长度为16比特，而普通的非压缩指令的长度为32比特。以上这些模块的一个特定组合“IMAFD”，也被称为“通用”组合，由英文字母G表示。因此RV32G表示RV32IMAFD，同理RV64G表示RV64IMAFD。

为了进一步减少面积，RISC-V架构还提供一种“嵌入式”架构，由英文字母E表示。该架构主要用于追求极低面积与功耗的深嵌入式场景。该架构仅需要支持16个通用整数寄存器，而非嵌入式的普通架构则需要支持32个通用整数寄存器。

通过以上的模块化指令集，能够选择不同的组合来满足不同的应用。譬如，追求小面积低功耗的嵌入式场景可以选择使用RV32EC架构；而大型的64位架构则可以选择RV64G。

除了上述的模块，还有若干的模块包括L、B、P、V和T等。这些扩展目前大多数还在不断完善和定义中，尚未最终确定，因此本文在此不做详细论述。

2.2 可配置的通用寄存器组

RISC-V架构支持32位或者64位的架构，32位架构由RV32表示，其每个通用寄存器的宽度为32比特；64位架构由RV64表示，其每个通用寄存器的宽度为64比特。

RISC-V架构的整数通用寄存器组，包含32个（I架构）或者16个（E架构）通用整数寄存器，其中整数寄存器0被预留为常数0，其他的31个（I架构）或者15个（E架构）为普通的通用整数寄存器。

如果使用了浮点模块（F或者D），则需要另外一个独立的浮点寄存器组，包含32个通用浮点寄存器。如果仅使用F模块的浮点指令子集，则每个通用浮点寄存器的宽度为32比特；如果使用了D模块的浮点指令子集，则每个通用浮点寄存器的宽度为64比特。

2.3 规整的指令编码

在流水线中能够尽早尽快的读取通用寄存器组，往往是处理器流水线设计的期望之一，这样可以提高处理器性能和优化时序。这个看似简单的道理在很多现存的商用RISC架构中都难以实现，因为经过多年反复修改不断添加新指令后，其指令编码中的寄存器索引位置变得非常的凌乱，给译码器造成了负担。

得益于后发优势和总结了多年来处理器发展的教训，RISC-V的指令集编码非常的规整，指令所需的通用寄存器的索引（Index）都被放在固定的位置，如图2所示。因此指令译码器（Instruction Decoder）可以非常便捷的译码出寄存器索引然后读取通用寄存器组（Register File，Regfile）。

2.4 简洁的存储器访问指令

与所有的RISC处理器架构一样，RISC-V架构使用专用的存储器读（Load）指令和存储器写（Store）指令访问存储器（Memory），其他的普通指令无法访问存储器，这种架构是RISC架构的常用的一个基本策略，这种策略使得处理器核的硬件设计变得简单。

存储器访问的基本单位是字节（Byte）。RISC-V的存储器读和存储器写指令支持一个字节（8位），半字（16位），单字（32位）为单位的存储器读写操作，如果是64位架构还可以支持一个双字（64位）为单位的存储器读写操作。

RISC-V架构的存储器访问指令还有如下显著特点：

为了提高存储器读写的性能，RISC-V架构推荐使用地址对齐的存储器读写操作，但是地址非对齐的存储器操作RISC-V架构也支持，处理器可以选择用硬件来支持，也可以选择用软件来支持。

由于现在的主流应用是小端格式（Little-Endian），RISC-V架构仅支持小端格式。有关小端格式和大端格式的定义和区别，本文在此不做过多介绍，若对此不甚了解的初学者可以自行查阅学习。

很多的RISC处理器都支持地址自增或者自减模式，这种自增或者自减的模式虽然能够提高处理器访问连续存储器地址区间的性能，但是也增加了设计处理器的难度。RISC-V架构的存储器读和存储器写指令不支持地址自增自减的模式。

RISC-V架构采用松散存储器模型（Relaxed Memory Model），松散存储器模型对于访问不同地址的存储器读写指令的执行顺序不作要求，除非使用明确的存储器屏障（Fence）指令加以屏蔽。

这些选择都清楚地反映了RISC-V架构力图简化基本指令集，从而简化硬件设计的哲学。RISC-V架构如此定义非常合理，能够达到能屈能伸的效果。譬如：对于低功耗的简单CPU，可以使用非常简单的硬件电路即可完成设计；而对于追求高性能的超标量处理器则可以通过复杂设计的动态硬件调度能力来提高性能。

2.5 高效的分支跳转指令

RISC-V架构有两条无条件跳转指令（Unconditional Jump），jal与jalr指令。跳转链接（Jump and Link）指令jal可用于进行子程序调用，同时将子程序返回地址存在链接寄存器（Link Register：由某一个通用整数寄存器担任）中。跳转链接寄存器（Jump and Link-Register）指令jalr指令能够用于子程序返回指令，通过将jal指令（跳转进入子程序）保存的链接寄存器用于jalr指令的基地址寄存器，则可以从子程序返回。

RISC-V架构有6条带条件跳转指令（Conditional Branch），这种带条件的跳转指令跟普通的运算指令一样直接使用2个整数操作数，然后对其进行比较，如果比较的条件满足时，则进行跳转。因此，此类指令将比较与跳转两个操作放到了一条指令里完成。

作为比较，很多的其他RISC架构的处理器需要使用两条独立的指令。第一条指令先使用比较指令，比较的结果被保存到状态寄存器之中；第二条指令使用跳转指令，判断前一条指令保存在状态寄存器当中的比较结果为真时则进行跳转。相比而言RISC-V的这种带条件跳转指令不仅减少了指令的条数，同时硬件设计上更加简单。

对于没有配备硬件分支预测器的低端CPU，为了保证其性能，RISC-V的架构明确要求其采用默认的静态分支预测机制，即：如果是向后跳转的条件跳转指令，则预测为“跳”；如果是向前跳转的条件跳转指令，则预测为“不跳”，并且RISC-V架构要求编译器也按照这种默认的静态分支预测机制来编译生成汇编代码，从而让低端的CPU也能得到不错的性能。

为了使硬件设计尽量简单，RISC-V架构特地定义了所有的带条件跳转指令跳转目标的偏移量（相对于当前指令的地址）都是有符号数，并且其符号位被编码在固定的位置。因此，这种静态预测机制在硬件上非常容易实现，硬件译码器可以轻松的找到这个固定的位置，并判断其是0还是1来判断其是正数还是负数，如果是负数则表示跳转的目标地址为当前地址减去偏移量，也就是向后跳转，则预测为“跳”。当然对于配备有硬件分支预测器的高端CPU，则可以采用高级的动态分支预测机制来保证性能。

2.6 简洁的子程序调用

为了理解此节，需先对一般RISC架构中程序调用子函数的过程予以介绍，其过程如下：

进入子函数之后需要用存储器写（Store）指令来将当前的上下文（通用寄存器等的值）保存到系统存储器的堆栈区内，这个过程通常称为“保存现场”。

在退出子程序之时，需要用存储器读（Load）指令来将之前保存的上下文（通用寄存器等的值）从系统存储器的堆栈区读出来，这个过程通常称为“恢复现场”。

“保存现场”和“恢复现场”的过程通常由编译器编译生成的指令来完成，使用高层语言（譬如C或者C++）开发的开发者对此可以不用太关心。高层语言的程序中直接写上一个子函数调用即可，但是这个底层发生的“保存现场”和“恢复现场”的过程却是实实在在地发生着（可以从编译出的汇编语言里面看到那些“保存现场”和“恢复现场”的汇编指令），并且还需要消耗若干的CPU执行时间。

为了加速这个“保存现场”和“恢复现场”的过程，有的RISC架构发明了一次写多个寄存器到存储器中（Store Multiple），或者一次从存储器中读多个寄存器出来（Load Multiple）的指令，此类指令的好处是一条指令就可以完成很多事情，从而减少汇编指令的代码量，节省代码的空间大小。但是此种“Load Multiple”和“Store Multiple”的弊端是会让CPU的硬件设计变得复杂，增加硬件的开销，也可能损伤时序使得CPU的主频无法提高，笔者在曾经设计此类处理器时便深受其苦。

RISC-V架构则放弃使用这种“Load Multiple”和“Store Multiple”指令。并解释，如果有的场合比较介意这种“保存现场”和“恢复现场”的指令条数，那么可以使用公用的程序库（专门用于保存和恢复现场）来进行，这样就可以省掉在每个子函数调用的过程中都放置数目不等的“保存现场”和“恢复现场”的指令。

此选择再次印证了RISC-V追求硬件简单的哲学，因为放弃“Load Multiple”和“Store Multiple”指令可以大幅简化CPU的硬件设计，对于低功耗小面积的CPU可以选择非常简单的电路进行实现，而高性能超标量处理器由于硬件动态调度能力很强，可以有强大的分支预测电路保证CPU能够快速的跳转执行，从而可以选择使用公用的程序库（专门用于保存和恢复现场）的方式减少代码量，但是同时达到高性能。

2.7 无条件码执行

很多早期的RISC架构发明了带条件码的指令，譬如在指令编码的头几位表示的是条件码（Conditional Code），只有该条件码对应的条件为真时，该指令才被真正执行。

这种将条件码编码到指令中的形式可以使得编译器将短小的循环编译成带条件码的指令，而不用编译成分支跳转指令。这样便减少了分支跳转的出现，一方面减少了指令的数目；另一方面也避免了分支跳转带来的性能损失。然而，这种“条件码”指令的弊端同样会使得CPU的硬件设计变得复杂，增加硬件的开销，也可能损伤时序使得CPU的主频无法提高，笔者在曾经设计此类处理器时便深受其苦。

RISC-V架构则放弃使用这种带“条件码”指令的方式，对于任何的条件判断都使用普通的带条件分支跳转指令。此选择再次印证了RISC-V追求硬件简单的哲学，因为放弃带“条件码”指令的方式可以大幅简化CPU的硬件设计，对于低功耗小面积的CPU可以选择非常简单的电路进行实现，而高性能超标量处理器由于硬件动态调度能力很强，可以有强大的分支预测电路保证CPU能够快速的跳转执行达到高性能。

2.8 无分支延迟槽

很多早期的RISC架构均使用了“分支延迟槽（Delay Slot）”，最具有代表性的便是MIPS架构，在很多经典的计算机体系结构教材中，均使用MIPS对分支延迟槽进行过介绍。分支延迟槽就是指在每一条分支指令后面紧跟的一条或者若干条指令不受分支跳转的影响，不管分支是否跳转，这后面的几条指令都一定会被执行。

早期的RISC架构很多采用了分支延迟槽诞生的原因主要是因为当时的处理器流水线比较简单，没有使用高级的硬件动态分支预测器，所以使用分支延迟槽能够取得可观的性能效果。然而，这种分支延迟槽使得CPU的硬件设计变得极为的别扭，CPU设计人员对此往往苦不堪言。

RISC-V架构则放弃了分支延迟槽，再次印证了RISC-V力图简化硬件的哲学，因为现代的高性能处理器的分支预测算法精度已经非常高，可以有强大的分支预测电路保证CPU能够准确的预测跳转执行达到高性能。而对于低功耗小面积的CPU，由于无需支持分支延迟槽，硬件得到极大简化，也能进一步减少功耗和提高时序。

2.9 无零开销硬件循环

很多RISC架构还支持零开销硬件循环（Zero Overhead Hardware Loop）指令，其思想是通过硬件的直接参与，通过设置某些循环次数寄存器（Loop Count），然后可以让程序自动地进行循环，每一次循环则Loop Count自动减1，这样持续循环直到Loop Count的值变成0，则退出循环。

之所以提出发明这种硬件协助的零开销循环是因为在软件代码中的for 循环（for i=0; i

然有得必有失，此类零开销硬件循环指令大幅地增加了硬件设计的复杂度。因此，零开销循环指令与RISC-V架构简化硬件的哲学是完全相反的，在RISC-V架构中自然没有使用此类零开销硬件循环指令。

2.10 简洁的运算指令

在本章第2.1节中曾经提到RISC-V架构使用模块化的方式组织不同的指令子集，最基本的整数指令子集（I字母表示）支持的运算包括加法、减法、移位、按位逻辑操作和比较操作。这些基本的运算操作能够通过组合或者函数库的方式完成更多的复杂操作（譬如乘除法和浮点操作），从而能够完成大多数的软件操作。

整数乘除法指令子集（M字母表示）支持的运算包括，有符号或者无符号的乘法和除法操作。乘法操作能够支持两个32位的整数相乘得到一个64位的结果；除法操作能够支持两个32位的整数相除得到一个32位的商与32位的余数。

单精度浮点指令子集（F字母表示）与双精度浮点指令子集（D字母表示）支持的运算包括浮点加减法，乘除法，乘累加，开平方根和比较等操作，同时提供整数与浮点，单精度与双精度浮点彼此之间的格式转换操作。

很多RISC架构的处理器在运算指令产生错误之时，譬如上溢（Overflow）、下溢（Underflow）、非规格化浮点数（Subnormal）和除零（Divide by Zero），都会产生软件异常。RISC-V架构的一个特殊之处是对任何的运算指令错误（包括整数与浮点指令）均不产生异常，而是产生某个特殊的默认值，同时，设置某些状态寄存器的状态位。RISC-V架构推荐软件通过其他方法来找到这些错误。再次清楚地反映了RISC-V架构力图简化基本的指令集，从而简化硬件设计的哲学。

2.11 优雅的压缩指令子集

基本的RISC-V基本整数指令子集（字母I表示 ）规定的指令长度均为等长的32位，这种等长指令定义使得仅支持整数指令子集的基本RISC-V CPU非常容易设计。但是等长的32位编码指令也会造成代码体积（Code Size）相对较大的问题。

为了满足某些对于代码体积要求较高的场景（譬如嵌入式领域），RISC-V定义了一种可选的压缩（Compressed）指令子集，由字母C表示，也可以由RVC表示。RISC-V具有后发优势，从一开始便规划了压缩指令，预留了足够的编码空间，16位长指令与普通的32位长指令可以无缝自由地交织在一起，处理器也没有定义额外的状态。

RISC-V压缩指令的另外一个特别之处是，16位指令的压缩策略是将一部分普通最常用的的32位指令中的信息进行压缩重排得到（譬如假设一条指令使用了两个同样的操作数索引，则可以省去其中一个索引的编码空间），因此每一条16位长的指令都能一一找到其对应的原始32位指令。因此，程序编译成为压缩指令仅在汇编器阶段就可以完成，极大的简化了编译器工具链的负担。

RISC-V架构的研究者进行了详细的代码体积分析，如图3所示，通过分析结果可以看出，RV32C的代码体积相比RV32的代码体积减少了百分之四十，并且与ARM，MIPS和x86等架构相比都有不错的表现。

2.12 特权模式

RISC-V架构定义了三种工作模式，又称特权模式（Privileged Mode）：

Machine Mode：机器模式，简称M Mode。

Supervisor Mode：监督模式，简称S Mode。

User Mode：用户模式，简称U Mode。

RISC-V架构定义M Mode为必选模式，另外两种为可选模式。通过不同的模式组合可以实现不同的系统。

RISC-V架构也支持几种不同的存储器地址管理机制，包括对于物理地址和虚拟地址的管理机制，使得RISC-V架构能够支持从简单的嵌入式系统（直接操作物理地址）到复杂的操作系统（直接操作虚拟地址）的各种系统。

2.13 CSR寄存器

RISC-V架构定义了一些控制和状态寄存器（Control and Status Register，CSR），用于配置或记录一些运行的状态。CSR寄存器是处理器核内部的寄存器，使用其自己的地址编码空间和存储器寻址的地址区间完全无关系。

CSR寄存器的访问采用专用的CSR指令，包括CSRRW、CSRRS、CSRRC、CSRRWI、CSRRSI以及CSRRCI指令。

2.14 中断和异常

中断和异常机制往往是处理器指令集架构中最为复杂而关键的部分。RISC-V架构定义了一套相对简单基本的中断和异常机制，但是也允许用户对其进行定制和扩展。

2.15 矢量指令子集

RISC-V架构目前虽然还没有定型矢量（Vector）指令子集，但是从目前的草案中已经可以看出，RISC-V矢量指令子集的设计理念非常的先进，由于后发优势及借助矢量架构多年发展成熟的结论，RISC-V架构将使用可变长度的矢量，而不是矢量定长的SIMD指令集（譬如ARM的NEON和Intel的MMX），从而能够灵活的支持不同的实现。追求低功耗小面积的CPU可以选择使用长度较短的硬件矢量进行实现，而高性能的CPU则可以选择较长的硬件矢量进行实现，并且同样的软件代码能够彼此兼容。

2.16 自定制指令扩展

除了上述阐述的模块化指令子集的可扩展、可选择，RISC-V架构还有一个非常重要的特性，那就是支持第三方的扩展。用户可以扩展自己的指令子集，RISC-V预留了大量的指令编码空间用于用户的自定义扩展，同时，还定义了四条Custom指令可供用户直接使用，每条Custom指令都有几个比特位的子编码空间预留，因此，用户可以直接使用四条Custom指令扩展出几十条自定义的指令。

2.17 总结与比较

处理器设计技术经过几十年的衍进，随着大规模集成电路设计技术的发展直至今天，呈现出如下特点：

由于高性能处理器的硬件调度能力已经非常强劲且主频很高，因此，硬件设计希望指令集尽可能的规整、简单，从而，使得处理器可以设计出更高的主频与更低的面积。

以IoT应用为主的极低功耗处理器更加苛求低功耗与低面积。

存储器的资源也比早期的RISC处理器更加丰富。

如上种种这些因素，使得很多早期的RISC架构设计理念（依据当时技术背景而诞生），时至今日不仅不能帮助现代处理器设计，反而成了负担桎梏。某些早期RISC架构定义的特性，一方面使得高性能处理器的硬件设计束手束脚；另一方面又使得极低功耗的处理器硬件设计背负不必要的复杂度。

得益于后发优势，全新的RISC-V架构能够规避所有这些已知的负担，同时，利用其先进的设计哲学，设计出一套“现代”的指令集。本节再次将其特点总结如表2所示。